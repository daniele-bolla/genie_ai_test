(function(t){function e(e){for(var a,s,r=e[0],m=e[1],c=e[2],l=0,y=[];l<r.length;l++)s=r[l],Object.prototype.hasOwnProperty.call(o,s)&&o[s]&&y.push(o[s][0]),o[s]=0;for(a in m)Object.prototype.hasOwnProperty.call(m,a)&&(t[a]=m[a]);p&&p(e);while(y.length)y.shift()();return i.push.apply(i,c||[]),n()}function n(){for(var t,e=0;e<i.length;e++){for(var n=i[e],a=!0,r=1;r<n.length;r++){var m=n[r];0!==o[m]&&(a=!1)}a&&(i.splice(e--,1),t=s(s.s=n[0]))}return t}var a={},o={app:0},i=[];function s(e){if(a[e])return a[e].exports;var n=a[e]={i:e,l:!1,exports:{}};return t[e].call(n.exports,n,n.exports,s),n.l=!0,n.exports}s.m=t,s.c=a,s.d=function(t,e,n){s.o(t,e)||Object.defineProperty(t,e,{enumerable:!0,get:n})},s.r=function(t){"undefined"!==typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(t,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(t,"__esModule",{value:!0})},s.t=function(t,e){if(1&e&&(t=s(t)),8&e)return t;if(4&e&&"object"===typeof t&&t&&t.__esModule)return t;var n=Object.create(null);if(s.r(n),Object.defineProperty(n,"default",{enumerable:!0,value:t}),2&e&&"string"!=typeof t)for(var a in t)s.d(n,a,function(e){return t[e]}.bind(null,a));return n},s.n=function(t){var e=t&&t.__esModule?function(){return t["default"]}:function(){return t};return s.d(e,"a",e),e},s.o=function(t,e){return Object.prototype.hasOwnProperty.call(t,e)},s.p="/vue_html_highlight/";var r=window["webpackJsonp"]=window["webpackJsonp"]||[],m=r.push.bind(r);r.push=e,r=r.slice();for(var c=0;c<r.length;c++)e(r[c]);var p=m;i.push([0,"chunk-vendors"]),n()})({0:function(t,e,n){t.exports=n("cd49")},"11ec":function(t,e,n){"use strict";var a=n("beda"),o=n.n(a);o.a},"1e93":function(t,e,n){},4397:function(t,e,n){"use strict";var a=n("1e93"),o=n.n(a);o.a},"55ae":function(t,e,n){"use strict";var a=n("ff22"),o=n.n(a);o.a},"5c0b":function(t,e,n){"use strict";var a=n("9c0c"),o=n.n(a);o.a},"6d50":function(t){t.exports=JSON.parse('{"a":[{"type":"paragraph","content":[{"type":"span","content":[{"type":"text","marks":[],"text":"1 INTRODUCTION"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontWeight":"bold"},"bold":true,"font":"Times New Roman"}}],"attrs":{"blockCSS":{}}},{"type":"paragraph","content":[{"type":"span","content":[],"attrs":{}}],"attrs":{"blockCSS":{}}},{"type":"paragraph","content":[{"type":"span","content":[{"type":"text","marks":[],"text":"Text classification is an important problem in Natural Language Processing (NLP). Real world use cases include spam filtering or e-mail categorization. It is a core component in more complex systems such as search and ranking. Recently, deep learning techniques based on neural networks have achieved state of the art results in various NLP applications. One of the main successes of deep learning is due to the effectiveness of recurrent networks for language modelling and their application to "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"speech recognition "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"and"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" machine translation"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" ("}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Mikolov"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":", 2012"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"). However, in other cases including several text classification problems, it has been shown that deep networks do not convincingly beat the prior state of the art techniques ("}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Wang & Manning, 2012; "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Joulin"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" et al., 2016"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"). "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}}],"attrs":{"blockCSS":{}}},{"type":"paragraph","content":[{"type":"span","content":[],"attrs":{}}],"attrs":{"blockCSS":{}}},{"type":"paragraph","content":[{"type":"span","content":[{"type":"text","marks":[],"text":"In spite of being (typically) orders of magnitude slower to train than traditional techniques based on n-grams, neural networks are often regarded as a promising alternative due to compact model sizes, in particular for "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"character based"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" models. This is important for applications that need to run on systems with limited memory"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"such as smartphones. This paper specifically addresses the compromise between classification accuracy and the model size. We extend our previous work implemented in the "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"fastText"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","textDecoration":"underline","textDecorationStyle":"solid"},"underline":{"val":"single","color":null},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" library"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"1. It is based on n-gram features, "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"dimensionality reduction"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic","fontWeight":"bold"},"bold":true,"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":", and a fast approximation of the "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"softmax"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" classifier ("}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Joulin"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" et al., 2016"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"). We show that a few key ingredients, namely feature pruning, quantization, hashing, and retraining, allow us to produce text classification models with tiny size, often less than 100kB when trained on several popular datasets, without noticeably sacrificing accuracy or speed."}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}}],"attrs":{"blockCSS":{}}},{"type":"paragraph","content":[{"type":"span","content":[],"attrs":{}}],"attrs":{"blockCSS":{}}},{"type":"paragraph","content":[{"type":"span","content":[{"type":"text","marks":[],"text":"We plan to publish the code and scripts required to reproduce our results as an extension of the "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"fastText"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" library, thereby providing strong reproducible baselines for text classifiers that optimize the compromise between the model size and accuracy. We hope that this will help the engineering community to improve existing applications by using more efficient models."}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}}],"attrs":{"alignment":"right","blockCSS":{"textAlign":"right"}}},{"type":"paragraph","content":[{"type":"span","content":[],"attrs":{}}],"attrs":{"blockCSS":{}}},{"type":"paragraph","content":[{"type":"span","content":[{"type":"text","marks":[],"text":"This paper is organized as follows. "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Section 2"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" introduces related "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"work,"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Section 3"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" describes our text classification model and explains how we drastically reduce the model size. "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Section 4"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" shows the effectiveness of our approach in experiments on multiple text classification benchmarks."}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}}],"attrs":{"blockCSS":{}}},{"type":"paragraph","content":[{"type":"span","content":[],"attrs":{}}],"attrs":{"blockCSS":{}}},{"type":"paragraph","content":[{"type":"span","content":[{"type":"text","marks":[],"text":"2 RELATED WORK "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontWeight":"bold"},"bold":true,"font":"Times New Roman"}}],"attrs":{"blockCSS":{}}},{"type":"paragraph","content":[{"type":"span","content":[],"attrs":{}}],"attrs":{"blockCSS":{}}},{"type":"paragraph","content":[{"type":"span","content":[{"type":"text","marks":[],"text":"Models for text classification. "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontWeight":"bold"},"bold":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Text classification is a problem that has its roots in many applications such as web search, information retrieval and document classification ("}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Deerwester"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" et al., 1990; Pang & Lee, 2008"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"). Linear classifiers often obtain state-of-the-art performance while being scalable ("}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Agarwal et al., 2014; "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Joachims"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":", 1998; "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Joulin"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" et al., 2016; McCallum & Nigam, 1998"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"). They are particularly interesting when associated with the right features ("}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Wang & Manning, 2012"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"). They usually require storing embeddings for words and n-grams, which makes them memory inefficient. "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}}],"attrs":{"blockCSS":{}}},{"type":"paragraph","content":[{"type":"span","content":[],"attrs":{}}],"attrs":{"blockCSS":{}}},{"type":"paragraph","content":[{"type":"span","content":[{"type":"text","marks":[],"text":"Compression of language models."}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontWeight":"bold"},"bold":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" Our work is related to compression of statistical language models. Classical approaches include feature pruning based on entropy ("}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Stolcke"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":", 2000"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":") and quantization. Pruning aims to keep only the most important n-grams in the model, leaving out those with probability lower than a specified threshold. Further, the individual n-grams can be compressed by quantizing the probability value, and by storing the n-gram itself more "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"efficiently than as a sequence of characters. Various strategies have been developed, for example using tree structures or hash functions, and are discussed in ("}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Talbot & "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Brants"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":", 2008"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"). "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}}],"attrs":{"blockCSS":{}}},{"type":"paragraph","content":[{"type":"span","content":[],"attrs":{}}],"attrs":{"blockCSS":{}}},{"type":"paragraph","content":[{"type":"span","content":[{"type":"text","marks":[],"text":"Compression for "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontWeight":"bold"},"bold":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"similarity estimation"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic","fontWeight":"bold"},"bold":true,"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" and "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontWeight":"bold"},"bold":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"search"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic","fontWeight":"bold"},"bold":true,"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":". "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontWeight":"bold"},"bold":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"There is a large body of literature on how to compress a set of vectors into compact codes, such that the comparison of two codes approximates a target similarity in the original space. The typical use-case of these methods considers an indexed dataset of compressed vectors, and a query for which we want to find the nearest "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"neighbors"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" in the indexed set. One of the most popular is "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Locality-sensitive hashing (LSH)"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" by "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Charikar"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" ("}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"2002"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"), which is a binarization technique based on random projections that approximates the cosine similarity between two vectors through a monotonous function of the Hamming distance between the two corresponding binary codes. In our paper, LSH refers to this binarization strategy"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"2. "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}}],"attrs":{"blockCSS":{}}},{"type":"paragraph","content":[{"type":"span","content":[],"attrs":{}}],"attrs":{"blockCSS":{}}},{"type":"paragraph","content":[{"type":"span","content":[{"type":"text","marks":[],"text":"Many subsequent works have improved this initial binarization technique, such as "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"spectal"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" hashing ("}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Weiss et al., 2009"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"), or Iterative Quantization (ITQ) ("}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Gong & "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Lazebnik"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":", 2011"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"), which learns a rotation matrix minimizing the quantization loss of the binarization. We refer the reader to two recent surveys by Wang et al. ("}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"2014"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":") and Wang et al. ("}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"2015"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":") for an overview of the binary hashing literature. Beyond these binarization strategies, more general quantization techniques derived from "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Jegou"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" et al. ("}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"2011"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":") offer better trade-offs between memory and the approximation of a distance estimator. The Product Quantization (PQ) method approximates the distances by calculating, in the compressed domain, the distance between their quantized approximations. "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}}],"attrs":{"blockCSS":{}}},{"type":"paragraph","content":[{"type":"span","content":[],"attrs":{}}],"attrs":{"blockCSS":{}}},{"type":"paragraph","content":[{"type":"span","content":[{"type":"text","marks":[],"text":"This method is statistically guaranteed to preserve the Euclidean distance between the vectors within an error bound directly related to the quantization error. The original PQ has been concurrently improved by Ge et al. ("}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"2013"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":") and "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Norouzi"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" & Fleet ("}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"2013"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"), who learn an orthogonal transform minimizing the overall quantization loss. In our paper, we will consider the Optimized Product Quantization (OPQ) variant ("}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Ge et al., 2013"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"). "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}}],"attrs":{"blockCSS":{}}},{"type":"paragraph","content":[{"type":"span","content":[],"attrs":{}}],"attrs":{"blockCSS":{}}},{"type":"paragraph","content":[{"type":"span","content":[{"type":"text","marks":[],"text":"Softmax"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic","fontWeight":"bold"},"bold":true,"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" approximation. "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontWeight":"bold"},"bold":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"The aforementioned works approximate either the Euclidean distance or the cosine similarity (both being equivalent in the case of unit-norm vectors). However, in the context of "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"fastText"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":", we are specifically interested in approximating the maximum inner product involved in a "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"softmax"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" layer. Several approaches derived from LSH have been recently proposed to achieve this goal, such as Asymmetric LSH by Shrivastava & Li ("}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"2014"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"), subsequently discussed by "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Neyshabur"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" & "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Srebro"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" ("}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"2015"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"). In our work, since we are not constrained to purely binary codes, we resort a more traditional encoding by employing a magnitude/direction parametrization of our vectors. "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Therefore"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" we only need to encode/compress an unitary d-dimensional vector, which fits the aforementioned LSH and PQ methods well. "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}}],"attrs":{"blockCSS":{}}},{"type":"paragraph","content":[{"type":"span","content":[],"attrs":{}}],"attrs":{"blockCSS":{}}},{"type":"paragraph","content":[{"type":"span","content":[{"type":"text","marks":[],"text":"Neural"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic","fontWeight":"bold"},"bold":true,"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" network compression models"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontWeight":"bold"},"bold":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":". Recently, several research efforts have been conducted to compress the parameters of architectures involved in computer vision, namely for state-of-"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"theart"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" Convolutional Neural Networks (CNNs) ("}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Han et al., 2016; Lin et al., 2015"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"). Some use vector quantization ("}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Gong et al., 2014"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":") while others binarize the network ("}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Courbariaux"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" et al., 2016"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"). "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"Denil"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" et al. ("}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"2013"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":") show that such classification models are easily compressed because they are overparametrized, which concurs with early observations by "}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"LeCun"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":" et al. ("}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":"1990"}],"attrs":{"textCSS":{"fontFamily":"Times New Roman","fontStyle":"italic"},"italic":true,"font":"Times New Roman"}},{"type":"span","content":[{"type":"text","marks":[],"text":")."}],"attrs":{"textCSS":{"fontFamily":"Times New Roman"},"font":"Times New Roman"}}],"attrs":{"blockCSS":{}}}]}')},"9c0c":function(t,e,n){},beda:function(t,e,n){},cd49:function(t,e,n){"use strict";n.r(e);n("e260"),n("e6cf"),n("cca6"),n("a79d");var a,o,i,s=n("2b0e"),r=function(){var t=this,e=t.$createElement,n=t._self._c||e;return n("div",{attrs:{id:"app"}},[n("DocWithHighlight")],1)},m=[],c=n("d4ec"),p=n("262e"),l=n("2caf"),y=n("9ab4"),f=n("60a3"),u=function(){var t=this,e=t.$createElement,n=t._self._c||e;return n("div",{staticClass:"container"},[n("with-highlight",{attrs:{query:t.query,replacement:t.replacement},scopedSlots:t._u([{key:"nav",fn:function(e){var a=e.nav,o=a.count,i=a.currentFocused,s=a.prev,r=a.next,m=a.replace,c=a.htmlContent;return[n("div",{domProps:{innerHTML:t._s(c)}}),n("nav",{staticClass:"nav"},[n("div",{staticClass:"nav__left"},[n("base-input",{attrs:{name:"find",placeholder:"Find"},model:{value:t.query,callback:function(e){t.query=e},expression:"query"}}),n("div",{staticClass:"nav__left__bottom"},[n("h6",[t._v(t._s(i)+" of "+t._s(o))]),n("div",[n("base-button",{attrs:{disabled:!(i>1),text:"Prev"},on:{click:s}}),n("base-button",{staticClass:"ml-4",attrs:{disabled:!(i<o),text:"Next"},on:{click:r}})],1)])],1),n("div",{staticClass:"nav__right"},[n("base-input",{attrs:{name:"replace",placeholder:"Replace"},scopedSlots:t._u([{key:"postaddon",fn:function(){return[n("base-button",{attrs:{disabled:!o||t.query==t.replacement,text:"replace"},on:{click:m},scopedSlots:t._u([{key:"postaddon",fn:function(){},proxy:!0}],null,!0)})]},proxy:!0}],null,!0),model:{value:t.replacement,callback:function(e){t.replacement=e},expression:"replacement"}})],1)])]}},{key:"content",fn:function(){return[n("doc-compiler",{attrs:{content:t.content}})]},proxy:!0}])})],1)},x=[],S=n("bee2"),h=function(){var t=this,e=t.$createElement,n=t._self._c||e;return n("button",{class:"btn btn--"+t.size+" btn--"+t.skin,attrs:{type:t.type},on:{click:function(e){return t.$emit("click")}}},[t.text?n("span",{staticClass:"btn__text"},[t._v(t._s(t.text))]):t._e()])},w=[];n("c96a");(function(t){t[t["small"]=0]="small",t[t["medium"]=1]="medium",t[t["large"]=2]="large",t[t["full"]=3]="full"})(a||(a={})),function(t){t[t["secondary"]=0]="secondary",t[t["primary"]=1]="primary",t[t["default"]=2]="default",t[t["transparent"]=3]="transparent"}(o||(o={})),function(t){t[t["button"]=0]="button",t[t["submit"]=1]="submit",t[t["reset"]=2]="reset"}(i||(i={}));var d=function(t){Object(p["a"])(n,t);var e=Object(l["a"])(n);function n(){return Object(c["a"])(this,n),e.apply(this,arguments)}return n}(f["c"]);Object(y["a"])([Object(f["b"])({default:""})],d.prototype,"text",void 0),Object(y["a"])([Object(f["b"])({default:"medium"})],d.prototype,"size",void 0),Object(y["a"])([Object(f["b"])({default:"primary"})],d.prototype,"skin",void 0),Object(y["a"])([Object(f["b"])({default:"button"})],d.prototype,"type",void 0),d=Object(y["a"])([f["a"]],d);var T=d,N=T,R=(n("55ae"),n("2877")),b=Object(R["a"])(N,h,w,!1,null,null,null),k=b.exports,g=function(){var t=this,e=t.$createElement,n=t._self._c||e;return n("div",[n("label",{attrs:{for:t.name}},[t._v(t._s(t.label)+" ")]),n("div",{class:{"input-group":t.preAddon||t.postAddon}},[t.preAddon?n("div",{staticClass:"input-group__prepend"},[t._t("preaddon")],2):t._e(),n("input",{staticClass:"input",class:{"input-group__input":t.preAddon||t.postAddon},attrs:{type:t.type,id:t.name,name:t.name,placeholder:t.placeholder,"aria-described":"describe-"+t.name},domProps:{value:t.value},on:{blur:function(e){return t.$emit("blur")},input:function(e){return t.$emit("input",e.target.value)}}}),t.postAddon?n("div",{staticClass:"input-group__append"},[t._t("postaddon")],2):t._e()])])},C=[],v=function(t){Object(p["a"])(n,t);var e=Object(l["a"])(n);function n(){return Object(c["a"])(this,n),e.apply(this,arguments)}return Object(S["a"])(n,[{key:"preAddon",get:function(){return!!this.$slots.preaddon}},{key:"postAddon",get:function(){return!!this.$slots.postaddon}}]),n}(f["c"]);Object(y["a"])([Object(f["b"])({required:!0})],v.prototype,"value",void 0),Object(y["a"])([Object(f["b"])({default:"text"})],v.prototype,"type",void 0),Object(y["a"])([Object(f["b"])({default:""})],v.prototype,"label",void 0),Object(y["a"])([Object(f["b"])({default:""})],v.prototype,"placeholder",void 0),Object(y["a"])([Object(f["b"])({required:!0})],v.prototype,"name",void 0),v=Object(y["a"])([f["a"]],v);var F=v,O=F,j=Object(R["a"])(O,g,C,!1,null,null,null),_=j.exports,q=(n("d81d"),n("13d5"),n("b64b"),n("5530")),W=n("53ca"),z=n("15fd"),L=n("3f08"),M=(n("99af"),n("ac1f"),n("5319"),function(t){var e=t.replace(/[-/\\^$*+?.()|[\]{}]/g,"\\$&");return e}),P=function(t){var e={"&":"&amp;","<":"&lt;",">":"&gt;",'"':"&quot;","'":"&apos;"},n=e[t]||t;return n},H=function(t){return t&&0==Object.keys(t).length},A=function(t,e,n){return e in t?t[e]():n},E=function(t){return Object.keys(t).reduce((function(e,n){var a=t[n];return e+="".concat(n,':"').concat(a,'";'),e}),"")},$=function(t){var e={paragraph:function(){return"p"},text:function(){return L["a"]}};return A(e,t,t)},I=function(t){var e=t||{},n=e.blockCSS,a=e.textCSS,o=Object(z["a"])(e,["blockCSS","textCSS"]),i=function(t){return Object.keys(t).reduce((function(e,n){var a=t[n];return e[n]=a&&"object"===Object(W["a"])(a)?E(a):a,e}),{})},s=a&&!H(a)?a:n;return{attrs:i(o),style:s}},D=function(t){Object(p["a"])(n,t);var e=Object(l["a"])(n);function n(){return Object(c["a"])(this,n),e.apply(this,arguments)}return Object(S["a"])(n,[{key:"render",value:function(t){var e=function e(n){var a=n.content,o=n.type,i=n.text,s=n.attrs,r=$(o),m=" "!=i&&i?i:" ",c=function(){return a&&a.length?a.map(e):m};return t(r,Object(q["a"])({},I(s)),c())},n=this.content.map(e);return t("div",n)}}]),n}(f["c"]);Object(y["a"])([Object(f["b"])()],D.prototype,"content",void 0),D=Object(y["a"])([f["a"]],D);var J=D,Q=function(){var t=this,e=t.$createElement,n=t._self._c||e;return n("div",[t._t("nav",null,{nav:{count:t.count,currentFocused:t.currentFocused,prev:t.prev,next:t.next,replace:t.replace}}),n("div",{ref:"doc"},[t._t("content")],2)],2)},B=[],G=(n("4de4"),n("4160"),n("a15b"),n("fb6a"),n("4d63"),n("25f0"),n("466d"),n("1276"),n("159b"),n("4f96")),V=(n("96cf"),n("1da1")),K=(n("d3b7"),function(t){var e;return clearTimeout(e),new Promise((function(n){e=setTimeout((function(){n(!0)}),t)}))}),U=function(t){var e="(?<!<[^>]*)",n="((?:\\s*(?:<\\/?\\w[^<>]*>)?\\s*)*)",a=t.split("").map(P).map(M).join(")".concat(n,"(")),o="".concat(e,"(").concat(a,")");return new RegExp("".concat(o),"gmi")},X=function(t){return t.match(new RegExp("<*?>","g"))},Y=function(t){Object(p["a"])(n,t);var e=Object(l["a"])(n);function n(){var t;return Object(c["a"])(this,n),t=e.apply(this,arguments),t.count=0,t.currentFocused=0,t}return Object(S["a"])(n,[{key:"onMatchChanged",value:function(){var t=Object(V["a"])(regeneratorRuntime.mark((function t(){var e,n,a,o;return regeneratorRuntime.wrap((function(t){while(1)switch(t.prev=t.next){case 0:if(this.query&&""!=this.query){t.next=5;break}return this.resetContent(),t.abrupt("return");case 5:if(e=U(this.query),n=this.originalContent.match(e),!n){t.next=16;break}return this.resetCount(),a=this.highlightContent(e),o=600,t.next=13,K(o);case 13:this.contentWrapper.innerHTML=a,t.next=17;break;case 16:this.resetContent();case 17:case"end":return t.stop()}}),t,this)})));function e(){return t.apply(this,arguments)}return e}()},{key:"resetCount",value:function(){this.count=0,this.currentFocused=0}},{key:"resetContent",value:function(){this.resetCount(),this.contentWrapper.innerHTML=this.originalContent}},{key:"prev",value:function(){this.currentFocused>1&&(this.currentFocused--,this.goToMatch(this.currentFocused))}},{key:"next",value:function(){this.currentFocused<this.count&&(this.currentFocused++,this.goToMatch(this.currentFocused))}},{key:"increaseCount",value:function(){this.count++}},{key:"goToMatch",value:function(t){var e;this.contentWrapper.querySelectorAll(".highlightText--focused").forEach((function(t){return null===t||void 0===t?void 0:t.classList.remove("highlightText--focused")})),null===(e=this.contentWrapper.querySelector(".highlightText_".concat(t)))||void 0===e||e.scrollIntoView({behavior:"smooth",block:"center",inline:"center"}),this.contentWrapper.querySelectorAll(".highlightText_".concat(t)).forEach((function(t){return null===t||void 0===t?void 0:t.classList.add("highlightText--focused")}))}},{key:"highlightContent",value:function(t){var e=this;return this.originalContent.replace(t,(function(t){for(var n=arguments.length,a=new Array(n>1?n-1:0),o=1;o<n;o++)a[o-1]=arguments[o];var i=a.reverse(),s=Object(G["a"])(i),r=s.slice(2);e.increaseCount();var m='<span class="highlightText highlightText_'.concat(e.count,'">'),c="</span>";return r.reverse().reduce((function(t,e){return t+=e&&!X(e)?"".concat(m).concat(e).concat(c):X(e)?e.replace(new RegExp("(?<!<[^>]*)","g"),(function(t){return" "==t?"".concat(m).concat(t).concat(c):t})):"",t}),"")}))}},{key:"replace",value:function(){var t=this,e=U(this.query),n=this.originalContent.match(e);if(!n||this.query===this.replacement)return!1;var a=this.originalContent.replace(e,(function(e){for(var n=arguments.length,a=new Array(n>1?n-1:0),o=1;o<n;o++)a[o-1]=arguments[o];var i=a.reverse(),s=Object(G["a"])(i),r=s.slice(2),m=r.reverse().filter((function(t){return t})),c=t.replacement.slice(m.length,t.replacement.length)||"";return m.reduce((function(e,n,a){var o=P(t.replacement[a]),i=" "==t.replacement[a-1];return e+=X(n)&&o?i?n+o:o+n:X(n)&&!o?"":o||"",e}),"")+c}));this.contentWrapper.innerHTML=a,this.originalContent=a}},{key:"clearContent",value:function(t){var e=t.innerHTML.replace(/<!--.*?-->/g,"").replace(/ fragment=".*?"/g,"").replace(/&nbsp;/g," ");return t.innerHTML=e,t}},{key:"mounted",value:function(){this.contentWrapper=this.clearContent(this.$refs.doc),this.originalContent=this.contentWrapper.innerHTML}}]),n}(f["c"]);Object(y["a"])([Object(f["b"])()],Y.prototype,"query",void 0),Object(y["a"])([Object(f["b"])()],Y.prototype,"replacement",void 0),Object(y["a"])([Object(f["d"])("query")],Y.prototype,"onMatchChanged",null),Y=Object(y["a"])([f["a"]],Y);var Z=Y,tt=Z,et=(n("11ec"),Object(R["a"])(tt,Q,B,!1,null,null,null)),nt=et.exports,at=n("6d50"),ot=n("e671"),it=n.n(ot),st=function(t){Object(p["a"])(n,t);var e=Object(l["a"])(n);function n(){var t;return Object(c["a"])(this,n),t=e.apply(this,arguments),t.content=at["a"],t.query="",t.replacement="",t}return Object(S["a"])(n,[{key:"mounted",value:function(){var t=document.querySelector(".nav");t&&it.a.add(t)}}]),n}(f["c"]);st=Object(y["a"])([Object(f["a"])({components:{WithHighlight:nt,DocCompiler:J,BaseButton:k,BaseInput:_}})],st);var rt=st,mt=rt,ct=(n("4397"),Object(R["a"])(mt,u,x,!1,null,null,null)),pt=ct.exports,lt=function(t){Object(p["a"])(n,t);var e=Object(l["a"])(n);function n(){return Object(c["a"])(this,n),e.apply(this,arguments)}return n}(f["c"]);lt=Object(y["a"])([Object(f["a"])({components:{DocWithHighlight:pt}})],lt);var yt=lt,ft=yt,ut=(n("5c0b"),Object(R["a"])(ft,r,m,!1,null,null,null)),xt=ut.exports;s["a"].config.productionTip=!1,new s["a"]({render:function(t){return t(xt)}}).$mount("#app")},ff22:function(t,e,n){}});
//# sourceMappingURL=app.200e2689.js.map